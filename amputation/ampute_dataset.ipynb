{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86233364-55fe-43cc-a3f5-d2be7ac1d2c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:18:37.991408Z",
     "iopub.status.busy": "2024-12-23T08:18:37.990263Z",
     "iopub.status.idle": "2024-12-23T08:18:39.736650Z",
     "shell.execute_reply": "2024-12-23T08:18:39.735572Z",
     "shell.execute_reply.started": "2024-12-23T08:18:37.991350Z"
    }
   },
   "outputs": [],
   "source": [
    "from miss_mech import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c26783-4a57-4c24-927c-d7af30ad5d22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T08:16:04.297382Z",
     "iopub.status.busy": "2024-07-11T08:16:04.297107Z",
     "iopub.status.idle": "2024-07-11T08:16:04.728732Z",
     "shell.execute_reply": "2024-07-11T08:16:04.727719Z",
     "shell.execute_reply.started": "2024-07-11T08:16:04.297363Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f1386a-7a95-435f-8eac-60485c9d3305",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:18:53.599475Z",
     "iopub.status.busy": "2024-12-23T08:18:53.598457Z",
     "iopub.status.idle": "2024-12-23T08:18:53.799837Z",
     "shell.execute_reply": "2024-12-23T08:18:53.798706Z",
     "shell.execute_reply.started": "2024-12-23T08:18:53.599396Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data_proc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m d_lst \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data_proc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data_proc'"
     ]
    }
   ],
   "source": [
    "d_lst = os.listdir('../data_proc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d83c993-2447-4a78-a52e-b3106fc20c43",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-07-11T08:17:13.312167Z",
     "iopub.status.busy": "2024-07-11T08:17:13.311336Z",
     "iopub.status.idle": "2024-07-11T08:17:30.212397Z",
     "shell.execute_reply": "2024-07-11T08:17:30.211468Z",
     "shell.execute_reply.started": "2024-07-11T08:17:13.312092Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raisin\n",
      "Numerical data; num: 7\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "wine\n",
      "Numerical data; num: 11\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "climate\n",
      "Mixed data; num: 19, cat: 1 \n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "yacht\n",
      "Categorical data; cat: 6\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "adult\n",
      "Mixed data; num: 6, cat: 9 \n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "default\n",
      "Mixed data; num: 14, cat: 10 \n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "diabetes\n",
      "Mixed data; num: 9, cat: 1 \n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "compression\n",
      "Mixed data; num: 7, cat: 1 \n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "news\n",
      "Mixed data; num: 46, cat: 2 \n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "beijing\n",
      "Mixed data; num: 7, cat: 5 \n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "magic\n",
      "Mixed data; num: 10, cat: 1 \n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "letter\n",
      "Categorical data; cat: 16\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "bike\n",
      "Mixed data; num: 9, cat: 3 \n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "obesity\n",
      "Mixed data; num: 8, cat: 8 \n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "shoppers\n",
      "Mixed data; num: 10, cat: 8 \n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MCAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n",
      "MNAR\n"
     ]
    }
   ],
   "source": [
    "## NEW PROC\n",
    "\n",
    "for id_ in range(len(d_lst)):\n",
    "    \n",
    "    \n",
    "    dataset, X_num, X_cat, categories, d_numerical, y, task_type, _, _ = torch.load(f'../data_proc/{d_lst[id_]}').values()\n",
    "\n",
    "    save_dir = f'../amputation/{dataset}'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    print(dataset)\n",
    "    if (X_cat is not None):\n",
    "        if (X_num is not None):\n",
    "            print(f'Mixed data; num: {X_num.shape[1]}, cat: {X_cat.shape[1]} ')\n",
    "    \n",
    "            normalizer = sklearn.preprocessing.QuantileTransformer(\n",
    "                                                output_distribution='normal',\n",
    "                                                n_quantiles=max(min(X_num.shape[0] // 30, 1000), 10),\n",
    "                                                subsample=int(1e9),\n",
    "                                                random_state=42,\n",
    "                                                )\n",
    "            X_num = torch.tensor(normalizer.fit(X_num).transform(X_num)).float()\n",
    "            \n",
    "            X_init = torch.cat([X_num, X_cat], axis = 1)\n",
    "            \n",
    "        else:\n",
    "            print(f'Categorical data; cat: {X_cat.shape[1]}')\n",
    "            X_init = X_cat\n",
    "                    \n",
    "    else:\n",
    "        print(f'Numerical data; num: {X_num.shape[1]}')\n",
    "        \n",
    "        normalizer = sklearn.preprocessing.QuantileTransformer(\n",
    "                                                output_distribution='normal',\n",
    "                                                n_quantiles=max(min(X_num.shape[0] // 30, 1000), 10),\n",
    "                                                subsample=int(1e9),\n",
    "                                                random_state=42,\n",
    "                                                )\n",
    "        X_num = torch.tensor(normalizer.fit(X_num).transform(X_num)).float()\n",
    "    \n",
    "        X_init = X_num\n",
    "\n",
    "    \n",
    "    simul_dict = {'X_init': X_init, 'X_num':X_num, 'X_cat': X_cat, 'y':y, 'task_type':task_type, 'd_numerical': d_numerical}\n",
    "    torch.save(simul_dict, f'{save_dir}/new_proc.pkl')\n",
    "\n",
    "    data_dict = {'MAR':{'0.3':{}, '0.6': {}}, \n",
    "                 'MCAR':{'0.3':{}, '0.6': {}}, \n",
    "                 'MNAR': {'0.3':{}, '0.6': {}}}\n",
    "    \n",
    "    \n",
    "    for mechanism in ['MAR', 'MCAR', 'MNAR']:\n",
    "        \n",
    "        \n",
    "        p_miss_r = 0.5\n",
    "        \n",
    "        for p_miss_c in [0.3, 0.6]:\n",
    "\n",
    "            data_dict[mechanism][p_miss_c] = {}\n",
    "            \n",
    "            for seed in range(5):\n",
    "\n",
    "                data_dict[mechanism][p_miss_c][seed] = {}\n",
    "                \n",
    "                \n",
    "                #seed = 1\n",
    "                print(mechanism)\n",
    "                \n",
    "                set_all_seeds(seed)\n",
    "                \n",
    "                # generate mask (missing); True : Miss, False: Obs\n",
    "                ps, mask, coeffs = generate_missing(X_num, X_cat, mechanism = mechanism, p = p_miss_r, p_obs_col = 1-p_miss_c, seed = seed)\n",
    "                \n",
    "                #print( (1.0*mask).mean(axis = 0) )\n",
    "                \n",
    "                X_incomp = X_init.clone().float()\n",
    "                X_incomp[mask.bool()] = np.nan\n",
    "                \n",
    "                X_incomp_num, X_incomp_cat = X_incomp[:, :d_numerical], X_incomp[:, d_numerical:]\n",
    "                miss_cols = torch.where(mask.float().mean(axis = 0) != 0)[0].tolist()\n",
    "                fully_obs_cols = [i for i in range(X_init.shape[1]) if i not in miss_cols]\n",
    "\n",
    "                \n",
    "                base_dict = {'X_incomp': X_incomp,\n",
    "                             'mask': mask,\n",
    "                             'full_cols': fully_obs_cols,\n",
    "                             'ps': ps}\n",
    "\n",
    "                data_dict[mechanism][p_miss_c][seed] = base_dict\n",
    "\n",
    "    # SAVE\n",
    "    torch.save(data_dict, f'{save_dir}/amputed.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daee0f48-6158-4cdf-b892-63f7925bfec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ba6f0-b90a-418e-982b-c334fa194787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## ORG PROC\n",
    "\n",
    "from miss_mech_rem import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def scale_data(X: pd.DataFrame):\n",
    "    preproc = MinMaxScaler()\n",
    "    cols = X.columns\n",
    "    return pd.DataFrame(preproc.fit_transform(X), columns=cols)\n",
    "    \n",
    "## ORG PROC\n",
    "\n",
    "for id_ in range(len(d_lst)):\n",
    "    \n",
    "    \n",
    "    dataset, X_num, X_cat, categories, d_numerical, y, task_type, _, _ = torch.load(f'../data_proc/{d_lst[id_]}').values()\n",
    "\n",
    "    save_dir = f'../amputation/{dataset}'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    print(dataset)\n",
    "    if (X_cat is not None):\n",
    "        if (X_num is not None):\n",
    "            print(f'Mixed data; num: {X_num.shape[1]}, cat: {X_cat.shape[1]} ')\n",
    "            X_init = torch.cat([X_num, X_cat], axis = 1)\n",
    "            \n",
    "        else:\n",
    "            print(f'Categorical data; cat: {X_cat.shape[1]}')\n",
    "            X_init = X_cat\n",
    "                    \n",
    "    else:\n",
    "        print(f'Numerical data; num: {X_num.shape[1]}')\n",
    "        X_init = X_num\n",
    "\n",
    "    # SCALING\n",
    "    X_init = torch.tensor(scale_data(pd.DataFrame(X_init.float())).values)\n",
    "    #X_init = scale_data(pd.DataFrame(X_init.float()))\n",
    "    \n",
    "    simul_dict = {'X_init': X_init, \n",
    "                  'X_num':X_init[:, :d_numerical] if d_numerical != 0 else None, \n",
    "                  'X_cat': X_init[:, d_numerical:] if X_cat is not None else None, \n",
    "                  'y':y,\n",
    "                  'task_type':task_type, \n",
    "                  'd_numerical': d_numerical}\n",
    "    \n",
    "    torch.save(simul_dict, f'{save_dir}/old_proc.pkl')\n",
    "\n",
    "    data_dict = {'MAR':{'0.3':{}, '0.6': {}}, \n",
    "                 'MCAR':{'0.3':{}, '0.6': {}}, \n",
    "                 'MNAR': {'0.3':{}, '0.6': {}}}\n",
    "    \n",
    "    \n",
    "    for mechanism in ['MAR', 'MCAR', 'MNAR']:\n",
    "        \n",
    "        \n",
    "        p_miss_r = 0.5\n",
    "        \n",
    "        for p_miss_c in [0.3, 0.6]:\n",
    "\n",
    "            data_dict[mechanism][p_miss_c] = {}\n",
    "            \n",
    "            for seed in range(5):\n",
    "\n",
    "                data_dict[mechanism][p_miss_c][seed] = {}\n",
    "               \n",
    "                #seed = 1\n",
    "                print(mechanism)\n",
    "                \n",
    "                set_all_seeds(seed)\n",
    "                \n",
    "                # generate mask (missing); True : Miss, False: Obs\n",
    "                #X_init, X_incomp, mask = simulate_nan(X_init.numpy(), p_miss = p_miss_c, mecha = mechanism, sample_columns = True).values()\n",
    "\n",
    "                X_init, X_incomp, mask = ampute(pd.DataFrame(X_init), \n",
    "                                mechanism = mechanism, \n",
    "                                p_miss = p_miss_r, \n",
    "                                p_miss_c = p_miss_c ,\n",
    "                                column_limit = max(round(p_miss_c * X_init.shape[1]), 1), \n",
    "                               seed = seed)\n",
    "                \n",
    "                \n",
    "                #print( (1.0*mask).mean(axis = 0) )\n",
    "\n",
    "                \n",
    "                X_incomp = torch.tensor(X_init.values).clone().float()\n",
    "                mask = torch.tensor(mask.values)\n",
    "                X_init = torch.tensor(X_init.values)\n",
    "\n",
    "                X_incomp[mask.bool()] = np.nan\n",
    "                \n",
    "                X_incomp_num, X_incomp_cat = X_incomp[:, :d_numerical], X_incomp[:, d_numerical:]\n",
    "                miss_cols = torch.where(mask.float().mean(axis = 0) != 0)[0].tolist()\n",
    "                fully_obs_cols = [i for i in range(X_init.shape[1]) if i not in miss_cols]\n",
    "                \n",
    "                base_dict = {'X_incomp': X_incomp,\n",
    "                             'mask': mask == 1,\n",
    "                             'full_cols': fully_obs_cols}\n",
    "\n",
    "                data_dict[mechanism][p_miss_c][seed] = base_dict\n",
    "\n",
    "    # SAVE\n",
    "    torch.save(data_dict, f'{save_dir}/amputed_org.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f2bcd1-321d-4087-81ca-14e7aff3c79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a3bbf4a-3f9f-4f68-83ab-ef18466c63ed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c64cc-dbef-4a3e-9405-38fdf19f4fdd",
   "metadata": {},
   "source": [
    "#### VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ab632-1b47-4528-b545-9cd8830e0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "mech = 'NMAR'\n",
    "seed = 213\n",
    "test_missing(X_num, X_cat, mechanism = mech, seed = seed, c = 0, v = 1, var_select = False, standardize = True)\n",
    "test_missing(X_num, X_cat, mechanism = mech, seed = seed, c = 0, v = 1, var_select = True, standardize = True)\n",
    "test_missing(X_num, X_cat, mechanism = mech, seed = seed, c = 0, v = 1, var_select = False, standardize = False)\n",
    "test_missing(X_num, X_cat, mechanism = mech, seed = seed, c = 2, v = 1, var_select = True, standardize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c38659-6d6b-4611-a68b-a05ebb7cd103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_missing(X_num, X_cat, mechanism = 'MAR', seed = 0, c = 0, v = 1, var_select = False, standardize = True):\n",
    "    p_miss_r = 0.5\n",
    "    p_miss_c = 0.8\n",
    "    #seed = 0\n",
    "    \n",
    "    set_all_seeds(seed)\n",
    "    \n",
    "    # generate mask (missing); True : Miss, False: Obs\n",
    "    ps, mask, coeffs = generate_missing(X_num, X_cat, mechanism = mechanism, p = p_miss_r, p_obs_col = 1-p_miss_c, seed = seed, c = c, v = v, var_select = var_select, standardize = standardize)\n",
    "    \n",
    "    #print( (1.0*mask).mean(axis = 0) )\n",
    "    \n",
    "    X_incomp = X_init.clone()\n",
    "    X_incomp[mask.bool()] = np.nan\n",
    "    \n",
    "    X_incomp_num, X_incomp_cat = X_incomp[:, :d_numerical], X_incomp[:, d_numerical:]\n",
    "    miss_cols = torch.where(mask.float().mean(axis = 0) != 0)[0].tolist()\n",
    "    fully_obs_cols = [i for i in range(X_init.shape[1]) if i not in miss_cols]\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 4, figsize = (16, 4))\n",
    "    ax_ = ax.flatten()\n",
    "    \n",
    "    for idx, axs in enumerate(ax_):\n",
    "        \n",
    "        miss_mask = mask[:, miss_cols[idx]]\n",
    "        obs_mask = mask[:, miss_cols[idx]] == False\n",
    "        X_obs = X_init[:, miss_cols][obs_mask, idx]\n",
    "        X_mis = X_init[:, miss_cols][miss_mask, idx]\n",
    "    \n",
    "        sns.histplot(X_obs, label = 'obs', bins = 20, stat = 'density', ax = axs)\n",
    "        sns.histplot(X_mis, label = 'mis', bins = 20, stat = 'density', ax = axs)\n",
    "    \n",
    "        axs.set_title(f'var = {idx}')\n",
    "    plt.suptitle(f'mech = {mechanism}')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54224a83-9806-4822-9a53-7d5052cda1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_missing(X_num, X_cat, mechanism = 'MAR', seed = 0, c = 0, v = 1, var_select = False, standardize = True):\n",
    "    \n",
    "    # generate mask (missing); True : Miss, False: Obs\n",
    "    ps, mask, coeffs = generate_missing(X_num, X_cat, mechanism = mechanism, p = p_miss_r, p_obs_col = 1-p_miss_c, seed = seed, c = c, v = v, var_select = var_select, standardize = standardize)\n",
    "    \n",
    "    #print( (1.0*mask).mean(axis = 0) )\n",
    "    \n",
    "    X_incomp = X_init.clone()\n",
    "    X_incomp[mask.bool()] = np.nan\n",
    "    \n",
    "    X_incomp_num, X_incomp_cat = X_incomp[:, :d_numerical], X_incomp[:, d_numerical:]\n",
    "    miss_cols = torch.where(mask.float().mean(axis = 0) != 0)[0].tolist()\n",
    "    fully_obs_cols = [i for i in range(X_init.shape[1]) if i not in miss_cols]\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 4, figsize = (16, 4))\n",
    "    ax_ = ax.flatten()\n",
    "    \n",
    "    for idx, axs in enumerate(ax_):\n",
    "        \n",
    "        miss_mask = mask[:, miss_cols[idx]]\n",
    "        obs_mask = mask[:, miss_cols[idx]] == False\n",
    "        X_obs = X_init[:, miss_cols][obs_mask, idx]\n",
    "        X_mis = X_init[:, miss_cols][miss_mask, idx]\n",
    "    \n",
    "        sns.histplot(X_obs, label = 'obs', bins = 20, stat = 'density', ax = axs)\n",
    "        sns.histplot(X_mis, label = 'mis', bins = 20, stat = 'density', ax = axs)\n",
    "    \n",
    "        axs.set_title(f'var = {idx}')\n",
    "    plt.suptitle(f'mech = {mechanism}')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f7930-612f-4c79-a503-cfe50cae0694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803124b9-534f-4d8e-a13e-2b18294422f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8e8f4-c940-4b2a-bd28-1f65a08fb72d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
